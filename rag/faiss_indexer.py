#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîç –°–û–ó–î–ê–ù–ò–ï –ò–ù–î–ï–ö–°–ê FAISS –î–õ–Ø –ë–´–°–¢–†–û–ì–û –ü–û–ò–°–ö–ê

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–∑–¥–∞–µ—Ç –∏–Ω–¥–µ–∫—Å FAISS –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
–ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º —á–∞–Ω–∫–æ–≤.

–ó–ê–ü–£–°–ö:
    python rag/faiss_indexer.py
"""

import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Any
import time

try:
    import faiss
except ImportError:
    print("WARNING: FAISS not installed. Install with:")
    print("   pip install faiss-cpu  (or faiss-gpu for GPU)")
    exit(1)


class FAISSIndexer:
    def __init__(self, embedding_dim: int = 768): # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è text-embedding-004
        """
        Args:
            embedding_dim: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        self.embedding_dim = embedding_dim
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º IVFFlat –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (nlist) –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–¥–æ–±—Ä–∞–Ω–æ –¥–ª—è –≤–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
        self.quantizer = faiss.IndexFlatL2(embedding_dim)
        self.index = faiss.IndexIVFFlat(self.quantizer, embedding_dim, 100) # 100 - —Ä–∞–∑—É–º–Ω–æ–µ —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        self.index.nprobe = 10 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–∏–∂–∞–π—à–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
    
    def load_embeddings(self, language: str = 'ru') -> Tuple[np.ndarray, Dict]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ .npz —Ñ–∞–π–ª–∞
        
        Args:
            language: 'ru' –∏–ª–∏ 'en'
            
        Returns:
            (embeddings_matrix, metadata)
        """
        metadata_file = f"rag/embeddings_metadata_{language}.json"
        npz_file = f"rag/embeddings_{language}.npz" # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ .npz
        
        print(f"Loading embeddings from {npz_file}...")
        if not Path(npz_file).exists():
            print(f"WARNING: File {npz_file} not found. Skipping {language}.")
            return None, None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ NPZ —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        npz_data = np.load(npz_file)
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –º–∞—Å—Å–∏–≤—ã –∏–∑ npz –≤ –æ–¥–∏–Ω
        embeddings_list = [npz_data[key] for key in sorted(npz_data.files) if key.startswith('embeddings_')]
        
        if not embeddings_list:
            print(f"ERROR: No embedding arrays found in {npz_file}. Skipping {language}.")
            return None, None
            
        embeddings = np.vstack(embeddings_list).astype('float32')
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {embeddings.shape[0]:,} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ {embeddings.shape[1]}")
        
        if not Path(metadata_file).exists():
            print(f"WARNING: File {metadata_file} not found. Skipping {language}.")
            return None, None
            
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
            
        return embeddings, metadata
        
    def build_index(self, embeddings: np.ndarray) -> faiss.Index:
        """
        –°—Ç—Ä–æ–∏—Ç FAISS –∏–Ω–¥–µ–∫—Å –∏–∑ –º–∞—Å—Å–∏–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.
        
        Args:
            embeddings: –º–∞—Å—Å–∏–≤ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            
        Returns:
            –ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π FAISS –∏–Ω–¥–µ–∫—Å
        """
        print(f"\nBuilding FAISS index for {embeddings.shape[0]:,} embeddings...")
        start_time = time.time()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –≤ –∏–Ω–¥–µ–∫—Å
        faiss.normalize_L2(embeddings)
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–∏–ø –∏–Ω–¥–µ–∫—Å–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        # IndexFlatL2 - –ø—Ä–æ—Å—Ç–æ–π, –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        # IndexIVFFlat - –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π, –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è
        if embeddings.shape[0] < 10000: # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–æ—Ä–æ–≥
            index = faiss.IndexFlatL2(self.embedding_dim)
            print(f"  üìç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è IndexFlatL2")
            index.add(embeddings)
        else:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è IndexIVFFlat —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è
            quantizer = faiss.IndexFlatL2(self.embedding_dim)
            nlist = min(100, int(np.sqrt(embeddings.shape[0]))) # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
            index = faiss.IndexIVFFlat(quantizer, self.embedding_dim, nlist, faiss.METRIC_L2)
            index.nprobe = min(50, nlist) # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            print(f"  üìç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è IndexIVFFlat —Å {nlist} –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏, nprobe={index.nprobe}")
            
            # –û–±—É—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
            if not index.is_trained:
                print("  Training IndexIVFFlat (may take some time)...")
                index.train(embeddings)
                print("  Training completed.")
            
            index.add(embeddings)
        
        elapsed = time.time() - start_time
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω –∑–∞ {elapsed:.1f} —Å–µ–∫")
        return index
    
    def save_index(self, index: faiss.Index, metadata: Dict, language: str = 'ru'):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç FAISS –∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª—ã.
        """
        index_file = f"rag/faiss_index_{language}.bin"
        metadata_file = f"rag/faiss_metadata_{language}.json"
        
        print(f"\nSaving index to {index_file}...")
        faiss.write_index(index, index_file)
        index_size = Path(index_file).stat().st_size / (1024*1024)
        print(f"‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {index_size:.2f} –ú–ë")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–Ω–¥–µ–∫—Å–∞
        metadata['embedding_model'] = "models/text-embedding-004"
        metadata['embedding_dim'] = self.embedding_dim
        metadata['total_embeddings'] = int(index.ntotal)

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        metadata_size = Path(metadata_file).stat().st_size / (1024*1024)
        print(f"Metadata saved: {metadata_size:.2f} MB")
        return index_file, metadata_file

    def process_language(self, language: str = 'ru') -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —è–∑—ã–∫–∞.
        """
        index_file = f"rag/faiss_index_{language}.bin"
        metadata_file_out = f"rag/faiss_metadata_{language}.json"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∏–Ω–¥–µ–∫—Å –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        if Path(index_file).exists() and Path(metadata_file_out).exists():
            index_size = Path(index_file).stat().st_size / (1024*1024)
            print(f"SKIP: Index and metadata for {language} already exist ({index_size:.2f} MB). Skipping.")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –∏—Ö –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            with open(metadata_file_out, 'r', encoding='utf-8') as f:
                existing_metadata = json.load(f)
            
            # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–¥—Å—á–∏—Ç–∞—Ç—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            total_embeddings = existing_metadata.get('total_embeddings')
            if total_embeddings is None:
                total_embeddings = 0
                if 'structure' in existing_metadata:
                    for book in existing_metadata['structure'].values():
                        for file_info in book.values():
                            total_embeddings += file_info.get('num_chunks', 0)
            
            return {
                'language': language,
                'total_embeddings': total_embeddings or 'N/A',
                'embedding_dim': existing_metadata.get('embedding_dim', self.embedding_dim),
                'index_file': index_file,
                'metadata_file': metadata_file_out
            }

        embeddings, metadata = self.load_embeddings(language)
        
        if embeddings is None or metadata is None:
            return None

        index = self.build_index(embeddings)
        index_file, metadata_file = self.save_index(index, metadata, language)
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å—é–¥–∞)
        # self.test_search(index, embeddings, metadata, language)
        
        stats = {
            'language': language,
            'total_embeddings': embeddings.shape[0],
            'embedding_dim': embeddings.shape[1],
            'index_file': index_file,
            'metadata_file': metadata_file
        }
        return stats


def process_all_languages():
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –æ–±–æ–∏—Ö —è–∑—ã–∫–æ–≤."""
    
    import sys
    
    print("="*70)
    print("FAISS INDEXER - START")
    print("="*70)
    
    indexer = FAISSIndexer(embedding_dim=768) # –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    
    all_stats = {}
    
    # CLI: python faiss_indexer.py [ru|en|all]
    langs = []
    if len(sys.argv) > 1:
        arg = sys.argv[1].lower()
        if arg in ('ru', 'en'):
            langs = [arg]
        else:
            langs = ['ru', 'en']
    else:
        langs = ['ru', 'en']

    for lang in langs:
        print(f"\nSTAGE: {lang.upper()} SCRIPTURES")
        print("-" * 70)
        stats = indexer.process_language(lang)
        if stats:
            all_stats[lang] = stats
    
    print("\n" + "="*70)
    if not all_stats:
        print("INDEXING FAILED OR SKIPPED.")
    else:
        print("INDEXING COMPLETED!")
    print("="*70)
    
    for lang, stats in all_stats.items():
        print(f"\n[STATS] {lang.upper()}:")
        if stats:
            total = stats['total_embeddings']
            total_str = f"{total:,}" if isinstance(total, (int, float)) else str(total)
            print(f"   Total embeddings: {total_str}")
            print(f"   Dim: {stats['embedding_dim']}")
            print(f"   Index: {stats['index_file']}")
            print(f"   Meta: {stats['metadata_file']}")
        else:
            print("   Skip (likely no embeddings).")
    
    if all_stats:
        print("\nRAG system is ready!")
        print("Now you can start the API server: python rag/rag_api_server.py")
    
    return all_stats


if __name__ == "__main__":
    process_all_languages()
