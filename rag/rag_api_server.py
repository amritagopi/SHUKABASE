#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üîé REST API –î–õ–Ø RAG –ü–û–ò–°–ö–ê

–≠—Ç–æ—Ç —Å–µ—Ä–≤–µ—Ä –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç API –¥–ª—è –ø–æ–∏—Å–∫–∞, –∏—Å–ø–æ–ª—å–∑—É—è —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π RAGEngine.
–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫–∞—á–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–Ω–¥–µ–∫—Å—ã), –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç.

–ó–∞–ø—É—Å–∫:
    python rag/rag_api_server.py
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import sys
import os
import json
import shutil
import zipfile
import requests
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rag.rag_engine import RAGEngine

# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ---
APP_NAME = "Shukabase"
DATA_ARCHIVE_ID = "1noqtdfABCV4xpVhlfmO4SlridrfQPkiO" # ID —Ñ–∞–π–ª–∞ –Ω–∞ Google Drive
REQUIRED_FILES = [
    "faiss_index_en.bin", "faiss_index_ru.bin",
    "faiss_metadata_en.json", "faiss_metadata_ru.json",
    "chunked_scriptures_en.json", "chunked_scriptures_ru.json",
    "bm25_index_en.pkl", "bm25_index_ru.pkl"
]

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º
if getattr(sys, 'frozen', False):
    # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –∫–∞–∫ exe (PyInstaller)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º AppData/Local/Shukabase/rag_data
    base_path = os.path.join(os.getenv('LOCALAPPDATA'), APP_NAME)
else:
    # –ï—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –∫–∞–∫ —Å–∫—Ä–∏–ø—Ç (Dev)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É rag
    base_path = os.path.dirname(os.path.abspath(__file__))

DATA_DIR = os.path.join(base_path, "rag_data") if getattr(sys, 'frozen', False) else base_path
CHAT_HISTORY_DIR = os.path.join(base_path, "chat_history")

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
log_dir = os.path.join(base_path, "logs")
if not os.path.exists(log_dir):
    os.makedirs(log_dir, exist_ok=True)

log_file = os.path.join(log_dir, "rag_api_server.log")

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s in %(module)s: %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ---
app = Flask(__name__)
CORS(app)
rag_engine_instance = None

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö ---

def download_file_from_google_drive(id, destination):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª —Å Google Drive —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤."""
    URL = "https://docs.google.com/uc?export=download"

    session = requests.Session()

    response = session.get(URL, params={'id': id}, stream=True)
    token = get_confirm_token(response)

    if token:
        params = {'id': id, 'confirm': token}
        response = session.get(URL, params=params, stream=True)

    save_response_content(response, destination)

def get_confirm_token(response):
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            return value
    return None

def save_response_content(response, destination):
    CHUNK_SIZE = 32768
    total_size = 0
    
    logger.info(f"‚¨áÔ∏è –ù–∞—á–∞–ª–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤ {destination}...")
    
    with open(destination, "wb") as f:
        for chunk in response.iter_content(CHUNK_SIZE):
            if chunk: # filter out keep-alive new chunks
                f.write(chunk)
                total_size += len(chunk)
                # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º —á–∞—Å—Ç–æ
                if total_size % (10 * 1024 * 1024) == 0: # –ö–∞–∂–¥—ã–µ 10 –ú–ë
                    print(f"Downloading... {total_size / (1024*1024):.1f} MB", flush=True)

    logger.info(f"‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –†–∞–∑–º–µ—Ä: {total_size / (1024*1024):.2f} MB")

def ensure_data_exists():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∫–∞—á–∏–≤–∞–µ—Ç –∏—Ö –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏."""
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR, exist_ok=True)

    missing_files = [f for f in REQUIRED_FILES if not os.path.exists(os.path.join(DATA_DIR, f))]

    if missing_files:
        logger.info(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö: {missing_files}")
        logger.info("‚è≥ –ù–∞—á–∏–Ω–∞—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
        
        # –°–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —á–µ—Ä–µ–∑ stdout (Tauri –º–æ–∂–µ—Ç —ç—Ç–æ —á–∏—Ç–∞—Ç—å)
        print("STATUS: DOWNLOADING_DATA", flush=True)
        
        zip_path = os.path.join(DATA_DIR, "shukabase_data.zip")
        
        try:
            download_file_from_google_drive(DATA_ARCHIVE_ID, zip_path)
            
            print("STATUS: EXTRACTING_DATA", flush=True)
            logger.info("üì¶ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞...")
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –ø—Ä—è–º–æ –≤ DATA_DIR
                # –í –∞—Ä—Ö–∏–≤–µ —Ñ–∞–π–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å –≤ –ø–∞–ø–∫–µ rag/ –∏–ª–∏ –≤ –∫–æ—Ä–Ω–µ. 
                # –ü—Ä–æ–≤–µ—Ä–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                file_list = zip_ref.namelist()
                is_nested = any(f.startswith('rag/') for f in file_list)
                
                zip_ref.extractall(DATA_DIR)
                
                # –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –±—ã–ª–∏ –≤ –ø–∞–ø–∫–µ rag/, –ø–µ—Ä–µ–º–µ—Å—Ç–∏–º –∏—Ö –≤ –∫–æ—Ä–µ–Ω—å DATA_DIR
                if is_nested:
                    nested_dir = os.path.join(DATA_DIR, 'rag')
                    if os.path.exists(nested_dir):
                        for item in os.listdir(nested_dir):
                            s = os.path.join(nested_dir, item)
                            d = os.path.join(DATA_DIR, item)
                            if os.path.exists(d):
                                if os.path.isdir(d):
                                    shutil.rmtree(d)
                                else:
                                    os.remove(d)
                            shutil.move(s, d)
                        os.rmdir(nested_dir)

            logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω—ã.")
            
            # –£–¥–∞–ª—è–µ–º –∞—Ä—Ö–∏–≤
            os.remove(zip_path)
            
        except Exception as e:
            logger.critical(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏/—Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}", exc_info=True)
            print(f"ERROR: DATA_DOWNLOAD_FAILED: {e}", flush=True)
            sys.exit(1)
    else:
        logger.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –º–µ—Å—Ç–µ.")

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
def initialize_engine():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç RAGEngine."""
    global rag_engine_instance
    if rag_engine_instance is None:
        logger.info("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAGEngine...")
        print("STATUS: INITIALIZING_ENGINE", flush=True)
        try:
            # –ü–µ—Ä–µ–¥–∞–µ–º DATA_DIR –∫–∞–∫ base_dir
            rag_engine_instance = RAGEngine(languages=['ru', 'en'], base_dir=DATA_DIR)
            logger.info("‚úÖ RAGEngine —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            print("STATUS: READY", flush=True)
        except Exception as e:
            logger.critical(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RAGEngine: {e}", exc_info=True)
            rag_engine_instance = None 

# --- –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã API ---

@app.route('/api/search', methods=['POST'])
def search():
    if rag_engine_instance is None:
        return jsonify({'success': False, 'error': 'RAG Engine –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.'}), 503

    try:
        data = request.json
        query = data.get('query', '').strip()
        language = data.get('language', 'ru')
        top_k = int(data.get('top_k', 10))
        
        logger.info(f"üì• –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: query='{query}', lang='{language}', top_k={top_k}")

        if not query:
            return jsonify({'success': False, 'error': '–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å'}), 400
        if language not in rag_engine_instance.languages:
            return jsonify({'success': False, 'error': f'–Ø–∑—ã–∫ {language} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è'}), 400

        use_reranking = data.get('use_reranking', True)
        expand_query = data.get('expand_query', True)
        vector_distance_threshold = data.get('vector_distance_threshold', None)
        
        search_results = rag_engine_instance.search(
            query=query,
            language=language,
            top_k=top_k,
            use_reranking=use_reranking,
            expand_query=expand_query,
            vector_distance_threshold=vector_distance_threshold
        )
        
        return jsonify(search_results), 200

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ /api/search: {e}", exc_info=True)
        return jsonify({'success': False, 'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'}), 500

@app.route('/api/keyword_search', methods=['POST'])
def keyword_search():
    """–ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)"""
    try:
        data = request.json
        query = data.get('query', '').strip()
        language = data.get('language', 'en')
        case_sensitive = data.get('case_sensitive', False)
        
        logger.info(f"üì• Keyword search request: query='{query}', lang='{language}'")

        if not query:
            return jsonify({'success': False, 'error': '–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å'}), 400
        if language not in rag_engine_instance.languages:
            return jsonify({'success': False, 'error': f'–Ø–∑—ã–∫ {language} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è'}), 400

        search_results = rag_engine_instance.keyword_search(
            query=query,
            language=language,
            case_sensitive=case_sensitive
        )
        
        return jsonify(search_results), 200

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —ç–Ω–¥–ø–æ–∏–Ω—Ç–µ /api/keyword_search: {e}", exc_info=True)
        return jsonify({'success': False, 'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'}), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    if rag_engine_instance:
        status = {
            'status': 'healthy',
            'engine_status': 'initialized',
            'loaded_languages': list(rag_engine_instance.indices.keys())
        }
        return jsonify(status), 200
    else:
        status = {
            'status': 'unhealthy',
            'engine_status': 'not_initialized',
            'error': 'RAGEngine failed to initialize. Check logs.'
        }
        return jsonify(status), 503

@app.route('/api/conversations', methods=['GET'])
def get_conversations():
    if not os.path.exists(CHAT_HISTORY_DIR):
        return jsonify([])

    conversations = []
    try:
        for filename in os.listdir(CHAT_HISTORY_DIR):
            if filename.endswith('.json'):
                filepath = os.path.join(CHAT_HISTORY_DIR, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        conversations.append({
                            'id': data.get('id'),
                            'title': data.get('title'),
                            'createdAt': data.get('createdAt')
                        })
                except (json.JSONDecodeError, IOError) as e:
                    logger.warning(f"Could not read or parse conversation file {filename}: {e}")
        
        conversations.sort(key=lambda x: x.get('createdAt', ''), reverse=True)
        return jsonify(conversations)

    except Exception as e:
        logger.error(f"Error listing conversations: {e}", exc_info=True)
        return jsonify({'success': False, 'error': 'Could not list conversations'}), 500

@app.route('/api/conversations/<string:conversation_id>', methods=['GET'])
def get_conversation_by_id(conversation_id):
    filepath = os.path.join(CHAT_HISTORY_DIR, f"{conversation_id}.json")
    if not os.path.exists(filepath):
        return jsonify({'success': False, 'error': 'Conversation not found'}), 404

    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return jsonify(data)
    except Exception as e:
        logger.error(f"Error reading conversation {conversation_id}: {e}", exc_info=True)
        return jsonify({'success': False, 'error': 'Could not read conversation file'}), 500

@app.route('/api/conversations', methods=['POST'])
def save_conversation():
    try:
        data = request.json
        conversation_id = data.get('id')
        if not conversation_id:
            return jsonify({'success': False, 'error': 'Conversation ID is required'}), 400

        if not os.path.exists(CHAT_HISTORY_DIR):
            os.makedirs(CHAT_HISTORY_DIR, exist_ok=True)

        filepath = os.path.join(CHAT_HISTORY_DIR, f"{conversation_id}.json")
        
        if 'title' not in data or 'createdAt' not in data or 'messages' not in data:
            return jsonify({'success': False, 'error': 'Missing required conversation fields'}), 400

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        logger.info(f"üíæ Conversation '{conversation_id}' saved successfully.")
        return jsonify({'success': True, 'id': conversation_id})

    except Exception as e:
        logger.error(f"Error saving conversation: {e}", exc_info=True)
        return jsonify({'success': False, 'error': 'Could not save conversation'}), 500

@app.route('/api/conversations/<string:conversation_id>', methods=['DELETE'])
def delete_conversation(conversation_id):
    filepath = os.path.join(CHAT_HISTORY_DIR, f"{conversation_id}.json")
    if not os.path.exists(filepath):
        return jsonify({'success': False, 'error': 'Conversation not found'}), 404

    try:
        os.remove(filepath)
        logger.info(f"üóëÔ∏è Conversation '{conversation_id}' deleted successfully.")
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error deleting conversation {conversation_id}: {e}", exc_info=True)
        return jsonify({'success': False, 'error': 'Could not delete conversation file'}), 500


# --- –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ ---
if __name__ == '__main__':
    logger.info("="*80)
    logger.info(f"üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ Shukabase AI. Data dir: {DATA_DIR}")
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —Å–∫–∞—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    ensure_data_exists()
    
    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–≤–∏–∂–æ–∫
    initialize_engine()
    
    if rag_engine_instance:
        logger.info("‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ –Ω–∞ http://localhost:5000")
        app.run(host='0.0.0.0', port=5000, debug=False)
    else:
        logger.critical("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞.")
        sys.exit(1)